# feishu_pusher.py
"""
é£ä¹¦æ¨é€æ¨¡å—
å°†æ–‡ç« æœç´¢ç»“æœæ¨é€åˆ°é£ä¹¦æœºå™¨äºº
"""

import json
import logging
import requests
import yaml
from typing import Dict, List, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class FeishuPusher:
    """é£ä¹¦æ¨é€å™¨ç±»"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–é£ä¹¦æ¨é€å™¨

        Args:
            config: é£ä¹¦é…ç½®å­—å…¸
        """
        self.config = config
        self.webhook_url = config['webhook_url']
        self.max_articles_per_push = config['push_config']['max_articles_per_push']
        self.include_abstract = config['push_config']['include_abstract']
        self.abstract_max_length = config['push_config']['abstract_max_length']
        self.include_ai_evaluation = config['push_config']['include_ai_evaluation']
        self.template = config['push_config']['template']
        self.language = config['push_config'].get('language', 'zh')  # é»˜è®¤ä¸­æ–‡

        # éªŒè¯é…ç½®
        if not self.webhook_url or self.webhook_url == "https://open.feishu.cn/open-apis/bot/v2/hook/your-webhook-id":
            logger.warning("âš ï¸ é£ä¹¦webhook URLæœªé…ç½®ï¼Œå°†è·³è¿‡æ¨é€")
            self.enabled = False
        else:
            self.enabled = True

    def push_articles(self, all_results: Dict[str, List[Dict[str, Any]]],
                     filtered_articles: List[Dict[str, Any]],
                     search_days: int) -> bool:
        """
        æ¨é€æ–‡ç« åˆ°é£ä¹¦ï¼ˆæŒ‰ä¸»é¢˜åˆ†æ‰¹æ¬¡æ¨é€ï¼‰

        Args:
            all_results: åŸå§‹æœç´¢ç»“æœï¼ŒæŒ‰æœŸåˆŠåˆ†ç»„
            filtered_articles: AIè¿‡æ»¤åçš„æ–‡ç« åˆ—è¡¨
            search_days: æœç´¢å¤©æ•°

        Returns:
            bool: æ¨é€æ˜¯å¦æˆåŠŸ
        """
        if not self.config.get('enabled', False) or not self.enabled:
            logger.info("é£ä¹¦æ¨é€å·²ç¦ç”¨")
            return True

        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¸»é¢˜åˆ†ç»„æ¨é€
            group_by_topic = self.config.get('push_config', {}).get('group_by_topic', True)
            
            if group_by_topic:
                # æŒ‰ä¸»é¢˜åˆ†ç»„å¹¶åˆ†æ‰¹æ¨é€
                return self._push_by_topics(all_results, filtered_articles, search_days)
            else:
                # åŸæœ‰æ¨é€æ–¹å¼ï¼ˆå•æ¬¡æ¨é€ï¼‰
                card_message = self._prepare_message(all_results, filtered_articles, search_days)
                return self._send_to_feishu(card_message)

        except Exception as e:
            logger.error(f"é£ä¹¦æ¨é€å¤±è´¥: {e}")
            return False

    def _format_single_article(self, article: Dict[str, Any], index: int) -> str:
        """
        æ ¼å¼åŒ–å•ç¯‡æ–‡ç« ä¸ºæ¨é€æ–‡æœ¬

        Args:
            article: æ–‡ç« ä¿¡æ¯
            index: æ–‡ç« åºå·

        Returns:
            str: æ ¼å¼åŒ–çš„æ–‡ç« æ–‡æœ¬
        """
        # åŸºæœ¬ä¿¡æ¯
        title = article.get('title', 'N/A')
        journal = article.get('journal', 'N/A')
        # æ˜¾ç¤ºæ‰€æœ‰ä½œè€…ï¼Œä¸æˆªæ–­
        authors_list = article.get('authors', [])
        if authors_list:
            authors = ', '.join(authors_list)
        else:
            authors = 'N/A'
        link = article.get('link', '')

        # AIè¯„ä¼°ä¿¡æ¯
        ai_info = ""
        if self.include_ai_evaluation and 'ai_evaluation' in article:
            eval_data = article['ai_evaluation']
            score = eval_data.get('score', 0)
            description = eval_data.get('description', '')
            application_areas = eval_data.get('application_areas', [])
            
            # æ„å»ºAIè¯„ä¼°ä¿¡æ¯
            ai_parts = [f"â­ è¯„åˆ†: {score}"]
            
            # æ·»åŠ åº”ç”¨é¢†åŸŸ
            if application_areas:
                areas_display = ', '.join(application_areas[:3])  # æœ€å¤šæ˜¾ç¤º3ä¸ªé¢†åŸŸ
                ai_parts.append(f"ğŸ”¬ é¢†åŸŸ: {areas_display}")
            
            # æ·»åŠ AIæ€»ç»“æè¿°
            if description:
                ai_parts.append(f"ï¿½ AIæ€»ç»“: {description}")
            
            ai_info = "\nğŸ¤– " + " | ".join(ai_parts)

        # æ‘˜è¦ä¿¡æ¯
        abstract_info = ""
        if self.include_abstract and article.get('abstract'):
            abstract = article['abstract']
            if self.abstract_max_length > 0 and len(abstract) > self.abstract_max_length:
                abstract = abstract[:self.abstract_max_length] + "..."
            abstract_info = f"\nğŸ“„ æ‘˜è¦: {abstract}"

        # æ ¼å¼åŒ–å•ç¯‡æ–‡ç« 
        article_text = f"""
{index}. {title}
   ğŸ“° æœŸåˆŠ: {journal}
   ğŸ‘¥ ä½œè€…: {authors}{ai_info}{abstract_info}
   ğŸ”— [æŸ¥çœ‹åŸæ–‡]({link})"""

        return article_text

    def _prepare_message(self, all_results: Dict[str, List[Dict[str, Any]]],
                        filtered_articles: List[Dict[str, Any]],
                        search_days: int) -> Dict[str, Any]:
        """
        å‡†å¤‡æ¨é€æ¶ˆæ¯å†…å®¹ï¼ˆå¡ç‰‡æ¶ˆæ¯æ ¼å¼ï¼‰

        Args:
            all_results: åŸå§‹æœç´¢ç»“æœ
            filtered_articles: è¿‡æ»¤åçš„æ–‡ç« 
            search_days: æœç´¢å¤©æ•°

        Returns:
            Dict[str, Any]: å¡ç‰‡æ¶ˆæ¯ç»“æ„
        """
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        journal_count = len(all_results)
        total_articles = sum(len(articles) for articles in all_results.values())

        # æ„å»ºå¡ç‰‡æ¶ˆæ¯
        return self._build_card_message(all_results, filtered_articles, search_days, 
                                       journal_count, total_articles)

    def _format_articles(self, articles: List[Dict[str, Any]]) -> str:
        """
        æ ¼å¼åŒ–æ–‡ç« åˆ—è¡¨ä¸ºé£ä¹¦æ¶ˆæ¯æ ¼å¼

        Args:
            articles: æ–‡ç« åˆ—è¡¨

        Returns:
            str: æ ¼å¼åŒ–çš„æ–‡ç« å†…å®¹
        """
        if not articles:
            return "ğŸ“­ æœ¬æ¬¡æœç´¢æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ç« "

        # é™åˆ¶æ¨é€æ–‡ç« æ•°é‡
        articles_to_push = articles[:self.max_articles_per_push]

        formatted_articles = []

        for i, article in enumerate(articles_to_push, 1):
            # åŸºæœ¬ä¿¡æ¯
            title = article.get('title', 'N/A')
            journal = article.get('journal', 'N/A')
            # æ˜¾ç¤ºæ‰€æœ‰ä½œè€…ï¼Œä¸æˆªæ–­
            authors_list = article.get('authors', [])
            if authors_list:
                authors = ', '.join(authors_list)
            else:
                authors = 'N/A'
            link = article.get('link', '')

            # AIè¯„ä¼°ä¿¡æ¯
            ai_info = ""
            if self.include_ai_evaluation and 'ai_evaluation' in article:
                eval_data = article['ai_evaluation']
                score = eval_data.get('score', 0)
                description = eval_data.get('description', '')
                application_areas = eval_data.get('application_areas', [])
                
                # æ„å»ºAIè¯„ä¼°ä¿¡æ¯
                ai_parts = [f"â­ è¯„åˆ†: {score}"]
                
                # æ·»åŠ åº”ç”¨é¢†åŸŸ
                if application_areas:
                    areas_display = ', '.join(application_areas[:3])  # æœ€å¤šæ˜¾ç¤º3ä¸ªé¢†åŸŸ
                    ai_parts.append(f"ğŸ”¬ é¢†åŸŸ: {areas_display}")
                
                # æ·»åŠ AIæ€»ç»“æè¿°
                if description:
                    ai_parts.append(f"ï¿½ AIæ€»ç»“: {description}")
                
                ai_info = "\nğŸ¤– **AIè¯„ä¼°**: " + " | ".join(ai_parts)

            # æ‘˜è¦ä¿¡æ¯
            abstract_info = ""
            if self.include_abstract and article.get('abstract'):
                abstract = article['abstract']
                if self.abstract_max_length > 0 and len(abstract) > self.abstract_max_length:
                    abstract = abstract[:self.abstract_max_length] + "..."
                abstract_info = f"\nğŸ“„ **æ‘˜è¦**: {abstract}"

            # æ ¼å¼åŒ–å•ç¯‡æ–‡ç« 
            article_text = f"""
{i}. **{title}**
   ğŸ“° **æœŸåˆŠ**: {journal}
   ğŸ‘¥ **ä½œè€…**: {authors}{ai_info}{abstract_info}
   ğŸ”— [æŸ¥çœ‹åŸæ–‡]({link})"""

            formatted_articles.append(article_text)

        return "\n".join(formatted_articles)

    def _format_article_markdown(self, article: Dict[str, Any], index: int) -> str:
        """
        æ ¼å¼åŒ–å•ç¯‡æ–‡ç« ä¸ºMarkdownæ ¼å¼

        Args:
            article: æ–‡ç« ä¿¡æ¯
            index: æ–‡ç« åºå·

        Returns:
            str: Markdownæ ¼å¼çš„æ–‡ç« å†…å®¹
        """
        # åŸºæœ¬ä¿¡æ¯
        title = article.get('title', 'N/A')
        journal = article.get('journal', 'N/A')
        # æ˜¾ç¤ºæ‰€æœ‰ä½œè€…ï¼Œä¸æˆªæ–­
        authors_list = article.get('authors', [])
        if authors_list:
            authors = ', '.join(authors_list)
        else:
            authors = 'N/A'
        link = article.get('link', '')
        
        # æ„å»ºæ–‡ç« å†…å®¹
        content_parts = [f"**{index}. {title}**"]
        journal_label = "ğŸ“° **Journal**: " if self.language == 'en' else "ğŸ“° **æœŸåˆŠ**: "
        authors_label = "ğŸ‘¥ **Authors**: " if self.language == 'en' else "ğŸ‘¥ **ä½œè€…**: "
        content_parts.append(f"{journal_label}{journal}")
        content_parts.append(f"{authors_label}{authors}")
        
        # AIè¯„ä¼°ä¿¡æ¯
        if self.include_ai_evaluation and 'ai_evaluation' in article:
            eval_data = article['ai_evaluation']
            score = eval_data.get('score', 0)
            description = eval_data.get('description', '')
            application_areas = eval_data.get('application_areas', [])
            
            # æ ¹æ®è¯­è¨€è®¾ç½®æ˜¾ç¤ºä¸åŒçš„æ ‡ç­¾
            if self.language == 'en':
                ai_parts = [f"â­ Score: {score}"]
                if application_areas:
                    areas_display = ', '.join(application_areas[:3])
                    ai_parts.append(f"ğŸ”¬ Areas: {areas_display}")
                if description:
                    ai_parts.append(f"ğŸ’¡ AI Summary: {description}")
                content_parts.append(f"ğŸ¤– **AI Evaluation**: {' | '.join(ai_parts)}")
            else:
                ai_parts = [f"â­ è¯„åˆ†: {score}"]
                if application_areas:
                    areas_display = ', '.join(application_areas[:3])
                    ai_parts.append(f"ğŸ”¬ é¢†åŸŸ: {areas_display}")
                if description:
                    ai_parts.append(f"ğŸ’¡ AIæ€»ç»“: {description}")
                content_parts.append(f"ğŸ¤– **AIè¯„ä¼°**: {' | '.join(ai_parts)}")
        
        # æ‘˜è¦ä¿¡æ¯
        if self.include_abstract and article.get('abstract'):
            abstract = article['abstract']
            if self.abstract_max_length > 0 and len(abstract) > self.abstract_max_length:
                abstract = abstract[:self.abstract_max_length] + "..."
            abstract_label = "ğŸ“„ **Abstract**: " if self.language == 'en' else "ğŸ“„ **æ‘˜è¦**: "
            content_parts.append(f"{abstract_label}{abstract}")
        
        # é“¾æ¥
        if link:
            link_text = "[View Article]({link})" if self.language == 'en' else "[æŸ¥çœ‹åŸæ–‡]({link})"
            content_parts.append(f"ğŸ”— {link_text.format(link=link)}")
        
        return "\n".join(content_parts)
    
    def _build_card_message(self, all_results: Dict[str, List[Dict[str, Any]]],
                           filtered_articles: List[Dict[str, Any]],
                           search_days: int,
                           journal_count: int,
                           total_articles: int) -> Dict[str, Any]:
        """
        æ„å»ºé£ä¹¦å¡ç‰‡æ¶ˆæ¯ç»“æ„

        Args:
            all_results: åŸå§‹æœç´¢ç»“æœ
            filtered_articles: è¿‡æ»¤åçš„æ–‡ç« 
            search_days: æœç´¢å¤©æ•°
            journal_count: æœŸåˆŠæ•°é‡
            total_articles: æ€»æ–‡ç« æ•°

        Returns:
            Dict[str, Any]: å¡ç‰‡æ¶ˆæ¯ç»“æ„
        """
        elements = []
        
        # æ ‡é¢˜éƒ¨åˆ†
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        if self.language == 'en':
            header_content = f"""**ğŸ“° Biological Article Push**

**ğŸ“Š Search Statistics**
- Journals searched: {journal_count}
- Candidate articles: {total_articles}
- After AI filtering: {len(filtered_articles)}
- Generated at: {timestamp}"""
        else:
            header_content = f"""**ğŸ“° ç”Ÿç‰©æ–‡ç« æ¨é€**

**ğŸ“Š æœç´¢ç»Ÿè®¡**
- æœç´¢æœŸåˆŠ: {journal_count} ä¸ª
- å€™é€‰æ–‡ç« : {total_articles} ç¯‡
- AIç­›é€‰å: {len(filtered_articles)} ç¯‡
- ç”Ÿæˆæ—¶é—´: {timestamp}"""
        
        elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": header_content
            }
        })
        
        # åˆ†éš”çº¿
        elements.append({"tag": "hr"})
        
        # æ–‡ç« åˆ—è¡¨
        if not filtered_articles:
            no_articles_msg = "ğŸ“­ No articles found matching the criteria" if self.language == 'en' else "ğŸ“­ æœ¬æ¬¡æœç´¢æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ç« "
            elements.append({
                "tag": "div",
                "text": {
                    "tag": "lark_md",
                    "content": no_articles_msg
                }
            })
        else:
            # é™åˆ¶æ¨é€æ–‡ç« æ•°é‡
            articles_to_push = filtered_articles[:self.max_articles_per_push]
            
            for i, article in enumerate(articles_to_push, 1):
                # æ¯ç¯‡æ–‡ç« ä½œä¸ºä¸€ä¸ªdiv
                article_content = self._format_article_markdown(article, i)
                elements.append({
                    "tag": "div",
                    "text": {
                        "tag": "lark_md",
                        "content": article_content
                    }
                })
                
                # æ–‡ç« ä¹‹é—´æ·»åŠ åˆ†éš”çº¿ï¼ˆé™¤äº†æœ€åä¸€ç¯‡ï¼‰
                if i < len(articles_to_push):
                    elements.append({"tag": "hr"})
        
        # åº•éƒ¨ä¿¡æ¯
        elements.append({"tag": "hr"})
        footer_text = "ğŸ¤– *AI Smart Filtering | Biological Article Push*" if self.language == 'en' else "ğŸ¤– *AIæ™ºèƒ½ç­›é€‰ | ç”Ÿç‰©æ–‡ç« æ¨é€*"
        elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": footer_text
            }
        })
        
        # æ„å»ºå¡ç‰‡æ¶ˆæ¯
        card_message = {
            "msg_type": "interactive",
            "card": {
                "config": {
                    "wide_screen_mode": True
                },
                "elements": elements
            }
        }
        
        return card_message

    def _group_articles_by_topic(self, articles: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """
        æŒ‰ä¸»é¢˜åˆ†ç»„æ–‡ç« 

        Args:
            articles: æ–‡ç« åˆ—è¡¨

        Returns:
            Dict[str, List[Dict]]: æŒ‰ä¸»é¢˜åˆ†ç»„çš„æ–‡ç« å­—å…¸
        """
        topic_groups = {}
        
        for article in articles:
            # è·å–æ–‡ç« çš„ä¸»é¢˜
            topic = "other"  # é»˜è®¤ä¸»é¢˜
            if 'ai_evaluation' in article:
                ai_eval = article['ai_evaluation']
                topic = ai_eval.get('topic', 'other')
            
            # æ ‡å‡†åŒ–ä¸»é¢˜åç§°
            topic = topic.lower().strip()
            if not topic or topic == '':
                topic = 'other'
            
            # æ·»åŠ åˆ°å¯¹åº”ä¸»é¢˜ç»„
            if topic not in topic_groups:
                topic_groups[topic] = []
            topic_groups[topic].append(article)
        
        return topic_groups
    
    def _push_by_topics(self, all_results: Dict[str, List[Dict[str, Any]]],
                       filtered_articles: List[Dict[str, Any]],
                       search_days: int) -> bool:
        """
        æŒ‰ä¸»é¢˜åˆ†æ‰¹æ¬¡æ¨é€æ–‡ç« 

        Args:
            all_results: åŸå§‹æœç´¢ç»“æœ
            filtered_articles: è¿‡æ»¤åçš„æ–‡ç« åˆ—è¡¨
            search_days: æœç´¢å¤©æ•°

        Returns:
            bool: æ¨é€æ˜¯å¦æˆåŠŸ
        """
        # æŒ‰ä¸»é¢˜åˆ†ç»„
        topic_groups = self._group_articles_by_topic(filtered_articles)
        
        logger.info(f"ğŸ“Š æ–‡ç« å·²æŒ‰ä¸»é¢˜åˆ†ç»„ï¼Œå…± {len(topic_groups)} ä¸ªä¸»é¢˜")
        for topic, articles in topic_groups.items():
            logger.info(f"  - {topic}: {len(articles)} ç¯‡æ–‡ç« ")
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        journal_count = len(all_results)
        total_articles = sum(len(articles) for articles in all_results.values())
        
        # æŒ‰ä¸»é¢˜é¡ºåºæ¨é€ï¼ˆæŒ‰æ–‡ç« æ•°é‡é™åºï¼‰
        sorted_topics = sorted(topic_groups.items(), key=lambda x: len(x[1]), reverse=True)
        
        all_success = True
        topic_index = 0
        
        for topic, topic_articles in sorted_topics:
            topic_index += 1
            topic_name_display = self._get_topic_display_name(topic)
            
            logger.info(f"ğŸ“¤ æ¨é€ä¸»é¢˜ [{topic_index}/{len(sorted_topics)}]: {topic_name_display} ({len(topic_articles)} ç¯‡æ–‡ç« )")
            
            # å¦‚æœè¯¥ä¸»é¢˜çš„æ–‡ç« è¶…è¿‡å•æ¡æ¶ˆæ¯é™åˆ¶ï¼Œéœ€è¦åˆ†æ‰¹æ¨é€
            if len(topic_articles) > self.max_articles_per_push:
                # åˆ†æ‰¹æ¨é€
                batch_count = (len(topic_articles) + self.max_articles_per_push - 1) // self.max_articles_per_push
                logger.info(f"  âš ï¸ ä¸»é¢˜æ–‡ç« æ•°é‡è¶…è¿‡é™åˆ¶ï¼Œå°†åˆ†ä¸º {batch_count} æ‰¹æ¨é€")
                
                for batch_idx in range(batch_count):
                    start_idx = batch_idx * self.max_articles_per_push
                    end_idx = min(start_idx + self.max_articles_per_push, len(topic_articles))
                    batch_articles = topic_articles[start_idx:end_idx]
                    
                    logger.info(f"  ğŸ“¨ æ¨é€ç¬¬ {batch_idx + 1}/{batch_count} æ‰¹ ({len(batch_articles)} ç¯‡æ–‡ç« )")
                    
                    # æ„å»ºè¯¥æ‰¹æ¬¡çš„æ¨é€æ¶ˆæ¯
                    card_message = self._build_topic_message(
                        all_results, batch_articles, search_days,
                        journal_count, total_articles, len(filtered_articles),
                        topic_name_display, batch_idx + 1, batch_count
                    )
                    
                    # å‘é€æ¨é€
                    if not self._send_to_feishu(card_message):
                        all_success = False
                        logger.error(f"  âŒ ä¸»é¢˜ {topic_name_display} ç¬¬ {batch_idx + 1} æ‰¹æ¨é€å¤±è´¥")
                    else:
                        logger.info(f"  âœ… ä¸»é¢˜ {topic_name_display} ç¬¬ {batch_idx + 1} æ‰¹æ¨é€æˆåŠŸ")
                    
                    # æ‰¹æ¬¡ä¹‹é—´ç¨ä½œå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                    if batch_idx < batch_count - 1:
                        import time
                        time.sleep(0.5)
            else:
                # å•æ‰¹æ¨é€
                card_message = self._build_topic_message(
                    all_results, topic_articles, search_days,
                    journal_count, total_articles, len(filtered_articles),
                    topic_name_display, 1, 1
                )
                
                if not self._send_to_feishu(card_message):
                    all_success = False
                    logger.error(f"  âŒ ä¸»é¢˜ {topic_name_display} æ¨é€å¤±è´¥")
                else:
                    logger.info(f"  âœ… ä¸»é¢˜ {topic_name_display} æ¨é€æˆåŠŸ")
        
        if all_success:
            logger.info(f"âœ… æ‰€æœ‰ä¸»é¢˜æ¨é€å®Œæˆï¼Œå…±æ¨é€ {len(sorted_topics)} ä¸ªä¸»é¢˜")
        else:
            logger.warning(f"âš ï¸ éƒ¨åˆ†ä¸»é¢˜æ¨é€å¤±è´¥ï¼Œå…± {len(sorted_topics)} ä¸ªä¸»é¢˜")
        
        return all_success
    
    def _get_topic_display_name(self, topic: str) -> str:
        """
        è·å–ä¸»é¢˜çš„æ˜¾ç¤ºåç§°

        Args:
            topic: ä¸»é¢˜åç§°

        Returns:
            str: æ˜¾ç¤ºåç§°
        """
        topic_names = {
            'single-cell': 'å•ç»†èƒåˆ†æ' if self.language == 'zh' else 'Single-cell Analysis',
            'genomics': 'åŸºå› ç»„å­¦' if self.language == 'zh' else 'Genomics',
            'proteomics': 'è›‹ç™½è´¨ç»„å­¦' if self.language == 'zh' else 'Proteomics',
            'metabolomics': 'ä»£è°¢ç»„å­¦' if self.language == 'zh' else 'Metabolomics',
            'network': 'ç½‘ç»œåˆ†æ' if self.language == 'zh' else 'Network Analysis',
            'simulation': 'æ¨¡æ‹Ÿå»ºæ¨¡' if self.language == 'zh' else 'Simulation',
            'foundation_model': 'åŸºç¡€æ¨¡å‹' if self.language == 'zh' else 'Foundation Model',
            'aging': 'è¡°è€ç ”ç©¶' if self.language == 'zh' else 'Aging',
            'other': 'å…¶ä»–' if self.language == 'zh' else 'Other'
        }
        return topic_names.get(topic.lower(), topic)
    
    def _build_topic_message(self, all_results: Dict[str, List[Dict[str, Any]]],
                            topic_articles: List[Dict[str, Any]],
                            search_days: int,
                            journal_count: int,
                            total_articles: int,
                            filtered_count: int,
                            topic_name: str,
                            batch_num: int = 1,
                            total_batches: int = 1) -> Dict[str, Any]:
        """
        æ„å»ºä¸»é¢˜æ¨é€æ¶ˆæ¯

        Args:
            all_results: åŸå§‹æœç´¢ç»“æœ
            topic_articles: è¯¥ä¸»é¢˜çš„æ–‡ç« åˆ—è¡¨
            search_days: æœç´¢å¤©æ•°
            journal_count: æœŸåˆŠæ•°é‡
            total_articles: æ€»æ–‡ç« æ•°
            filtered_count: è¿‡æ»¤åæ–‡ç« æ€»æ•°
            topic_name: ä¸»é¢˜åç§°
            batch_num: å½“å‰æ‰¹æ¬¡å·
            total_batches: æ€»æ‰¹æ¬¡æ•°

        Returns:
            Dict[str, Any]: å¡ç‰‡æ¶ˆæ¯ç»“æ„
        """
        elements = []
        
        # æ ‡é¢˜éƒ¨åˆ†
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        if self.language == 'en':
            header_content = f"""**ğŸ“° Biological Article Push - {topic_name}**

**ğŸ“Š Search Statistics**
- Journals searched: {journal_count}
- Candidate articles: {total_articles}
- After AI filtering: {filtered_count}
- Topic: {topic_name} ({len(topic_articles)} articles)"""
            if total_batches > 1:
                header_content += f"\n- Batch: {batch_num}/{total_batches}"
            header_content += f"\n- Generated at: {timestamp}"""
        else:
            header_content = f"""**ğŸ“° ç”Ÿç‰©æ–‡ç« æ¨é€ - {topic_name}**

**ğŸ“Š æœç´¢ç»Ÿè®¡**
- æœç´¢æœŸåˆŠ: {journal_count} ä¸ª
- å€™é€‰æ–‡ç« : {total_articles} ç¯‡
- AIç­›é€‰å: {filtered_count} ç¯‡
- ä¸»é¢˜: {topic_name} ({len(topic_articles)} ç¯‡)"""
            if total_batches > 1:
                header_content += f"\n- æ‰¹æ¬¡: {batch_num}/{total_batches}"
            header_content += f"\n- ç”Ÿæˆæ—¶é—´: {timestamp}"""
        
        elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": header_content
            }
        })
        
        # åˆ†éš”çº¿
        elements.append({"tag": "hr"})
        
        # æ–‡ç« åˆ—è¡¨
        if not topic_articles:
            no_articles_msg = "ğŸ“­ No articles found" if self.language == 'en' else "ğŸ“­ æœªæ‰¾åˆ°æ–‡ç« "
            elements.append({
                "tag": "div",
                "text": {
                    "tag": "lark_md",
                    "content": no_articles_msg
                }
            })
        else:
            for i, article in enumerate(topic_articles, 1):
                # æ¯ç¯‡æ–‡ç« ä½œä¸ºä¸€ä¸ªdiv
                article_content = self._format_article_markdown(article, i)
                elements.append({
                    "tag": "div",
                    "text": {
                        "tag": "lark_md",
                        "content": article_content
                    }
                })
                
                # æ–‡ç« ä¹‹é—´æ·»åŠ åˆ†éš”çº¿ï¼ˆé™¤äº†æœ€åä¸€ç¯‡ï¼‰
                if i < len(topic_articles):
                    elements.append({"tag": "hr"})
        
        # åº•éƒ¨ä¿¡æ¯
        elements.append({"tag": "hr"})
        footer_text = f"ğŸ¤– *AI Smart Filtering | {topic_name}*" if self.language == 'en' else f"ğŸ¤– *AIæ™ºèƒ½ç­›é€‰ | {topic_name}*"
        elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": footer_text
            }
        })
        
        # æ„å»ºå¡ç‰‡æ¶ˆæ¯
        card_message = {
            "msg_type": "interactive",
            "card": {
                "config": {
                    "wide_screen_mode": True
                },
                "elements": elements
            }
        }
        
        return card_message

    def _send_to_feishu(self, card_message: Dict[str, Any]) -> bool:
        """
        å‘é€å¡ç‰‡æ¶ˆæ¯åˆ°é£ä¹¦

        Args:
            card_message: å¡ç‰‡æ¶ˆæ¯ç»“æ„

        Returns:
            bool: å‘é€æ˜¯å¦æˆåŠŸ
        """
        try:
            headers = {
                "Content-Type": "application/json"
            }

            response = requests.post(
                self.webhook_url,
                headers=headers,
                json=card_message,
                timeout=30
            )

            response.raise_for_status()

            result = response.json()
            if result.get('code') == 0:
                logger.info("âœ… é£ä¹¦æ¨é€æˆåŠŸ")
                return True
            else:
                logger.error(f"é£ä¹¦æ¨é€å¤±è´¥: {result}")
                return False

        except requests.exceptions.RequestException as e:
            logger.error(f"é£ä¹¦æ¨é€ç½‘ç»œé”™è¯¯: {e}")
            return False
        except Exception as e:
            logger.error(f"é£ä¹¦æ¨é€æœªçŸ¥é”™è¯¯: {e}")
            return False


def create_feishu_pusher(config: Dict[str, Any]) -> FeishuPusher:
    """
    ä»é…ç½®åˆ›å»ºé£ä¹¦æ¨é€å™¨

    Args:
        config: å®Œæ•´é…ç½®å­—å…¸

    Returns:
        FeishuPusher: é£ä¹¦æ¨é€å™¨å®ä¾‹
    """
    feishu_config = config.get('feishu', {})
    return FeishuPusher(feishu_config)


def push_to_feishu(all_results: Dict[str, List[Dict[str, Any]]],
                  filtered_articles: List[Dict[str, Any]],
                  search_days: int,
                  config: Dict[str, Any]) -> bool:
    """
    æ¨é€æ–‡ç« åˆ°é£ä¹¦çš„ä¾¿æ·å‡½æ•°

    Args:
        all_results: åŸå§‹æœç´¢ç»“æœ
        filtered_articles: è¿‡æ»¤åçš„æ–‡ç« 
        search_days: æœç´¢å¤©æ•°
        config: é…ç½®å­—å…¸

    Returns:
        bool: æ¨é€æ˜¯å¦æˆåŠŸ
    """
    pusher = create_feishu_pusher(config)
    return pusher.push_articles(all_results, filtered_articles, search_days)

