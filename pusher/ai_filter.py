# ai_filter.py
"""
AIè¾…åŠ©æ–‡ç« è¿‡æ»¤æ¨¡å—
ä½¿ç”¨AIæ¨¡å‹å¯¹æ–‡ç« è¿›è¡Œæ™ºèƒ½ç­›é€‰å’Œè¯„ä¼°
"""

import json
import os
import logging
import yaml
import requests
from typing import Dict, List, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class AIFilter:
    """AIè¿‡æ»¤å™¨ç±»"""

class AIFilter:
    """AIè¿‡æ»¤å™¨ç±»"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–AIè¿‡æ»¤å™¨

        Args:
            config: AIé…ç½®å­—å…¸
        """
        self.config = config
        self.provider = config['model']['provider']
        self.model_name = config['model']['name']
        self.base_url = config['model']['base_url']
        self.demo_mode = config.get('demo_mode', False)  # æ¼”ç¤ºæ¨¡å¼
        
        # åœ¨æ¼”ç¤ºæ¨¡å¼ä¸‹ä¸éœ€è¦API key
        if self.demo_mode:
            self.api_key = "demo"
        else:
            self.api_key = self._resolve_api_key(config['model']['api_key'])
            
        self.temperature = config['model']['temperature']
        self.max_tokens = config['model']['max_tokens']
        self.prompt_template = config['prompt']
        self.language = config.get('language', 'zh')  # é»˜è®¤ä¸­æ–‡

        # éªŒè¯é…ç½®
        if not self.demo_mode and not self.api_key:
            raise ValueError("API keyæœªè®¾ç½®ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œæˆ–å¯ç”¨demo_mode")

    def _resolve_api_key(self, api_key_config: str) -> str:
        """
        è§£æAPI keyï¼Œæ”¯æŒç¯å¢ƒå˜é‡

        Args:
            api_key_config: API keyé…ç½®å­—ç¬¦ä¸²

        Returns:
            str: è§£æåçš„API key
        """
        if api_key_config.startswith("${") and api_key_config.endswith("}"):
            env_var = api_key_config[2:-1]
            api_key = os.getenv(env_var)
            if not api_key:
                raise ValueError(f"ç¯å¢ƒå˜é‡ {env_var} æœªè®¾ç½®")
            return api_key
        return api_key_config

    def filter_articles(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨AIè¿‡æ»¤æ–‡ç« åˆ—è¡¨

        Args:
            articles: æ–‡ç« åˆ—è¡¨

        Returns:
            List[Dict]: è¿‡æ»¤åçš„æ–‡ç« åˆ—è¡¨ï¼ˆåŒ…å«AIè¯„ä¼°ç»“æœï¼‰
        """
        if not self.config.get('enabled', False):
            logger.info("AIè¿‡æ»¤å·²ç¦ç”¨ï¼Œè¿”å›æ‰€æœ‰æ–‡ç« ")
            return articles

        logger.info(f"å¼€å§‹AIè¿‡æ»¤ï¼Œå…± {len(articles)} ç¯‡æ–‡ç« ")

        filtered_articles = []

        for i, article in enumerate(articles):
            logger.info(f"AIè¯„ä¼°æ–‡ç«  {i+1}/{len(articles)}: {article['title'][:50]}...")

            try:
                # AIè¯„ä¼°æ–‡ç« 
                ai_result = self._evaluate_article(article)

                # æ·»åŠ AIè¯„ä¼°ç»“æœåˆ°æ–‡ç« 
                article_with_ai = article.copy()
                article_with_ai['ai_evaluation'] = ai_result

                # å¦‚æœæ–‡ç« ç›¸å…³ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
                if ai_result.get('relevant', False):
                    filtered_articles.append(article_with_ai)
                    logger.info(f"âœ“ æ–‡ç« é€šè¿‡AIè¿‡æ»¤ (è¯„åˆ†: {ai_result.get('score', 0)})")
                else:
                    logger.info(f"âœ— æ–‡ç« è¢«AIè¿‡æ»¤ (è¯„åˆ†: {ai_result.get('score', 0)})")

            except Exception as e:
                logger.error(f"AIè¯„ä¼°æ–‡ç« å¤±è´¥: {e}")
                # å¦‚æœAIè¯„ä¼°å¤±è´¥ï¼Œé»˜è®¤ä¿ç•™æ–‡ç« 
                article_with_ai = article.copy()
                article_with_ai['ai_evaluation'] = {
                    'relevant': True,  # é»˜è®¤ä¿ç•™
                    'score': 5,
                    'reason': f'AIè¯„ä¼°å¤±è´¥: {str(e)}',
                    'tags': []
                }
                filtered_articles.append(article_with_ai)

        logger.info(f"AIè¿‡æ»¤å®Œæˆï¼Œä¿ç•™ {len(filtered_articles)}/{len(articles)} ç¯‡æ–‡ç« ")
        return filtered_articles

    def _evaluate_article(self, article: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä½¿ç”¨AIè¯„ä¼°å•ç¯‡æ–‡ç« 

        Args:
            article: æ–‡ç« ä¿¡æ¯å­—å…¸

        Returns:
            Dict: AIè¯„ä¼°ç»“æœ
        """
        # å‡†å¤‡æç¤ºè¯
        prompt = self._prepare_prompt(article)

        # è°ƒç”¨AI API
        # ä¼˜å…ˆå°è¯•ä½¿ç”¨ç‰¹å®šæä¾›å•†çš„å®ç°ï¼ˆå¦‚æœæœ‰ç‰¹æ®Šéœ€æ±‚ï¼‰
        provider_lower = self.provider.lower()
        specific_method = f"_call_{provider_lower}_api"
        
        if hasattr(self, specific_method):
            # ä½¿ç”¨ç‰¹å®šæä¾›å•†çš„å®ç°
            method = getattr(self, specific_method)
            return method(prompt)
        else:
            # ä½¿ç”¨é€šç”¨APIè°ƒç”¨æ–¹æ³•ï¼ˆé€‚ç”¨äºæ‰€æœ‰OpenAIå…¼å®¹çš„APIï¼‰
            return self._call_generic_api(prompt)

    def _prepare_prompt(self, article: Dict[str, Any]) -> str:
        """
        å‡†å¤‡AIæç¤ºè¯

        Args:
            article: æ–‡ç« ä¿¡æ¯

        Returns:
            str: æ ¼å¼åŒ–çš„æç¤ºè¯
        """
        # æå–æ–‡ç« ä¿¡æ¯
        title = article.get('title', 'N/A')
        abstract = article.get('abstract', 'N/A')
        journal = article.get('journal', 'N/A')
        authors = ', '.join(article.get('authors', [])) if article.get('authors') else 'N/A'

        # æ ¹æ®è¯­è¨€è®¾ç½®è°ƒæ•´æç¤ºè¯
        prompt = self.prompt_template
        language_name = "English" if self.language == 'en' else "Chinese"
        
        # æ›¿æ¢è¯­è¨€å ä½ç¬¦
        prompt = prompt.replace("{language}", language_name)
        if self.language == 'en':
            # å°†æç¤ºè¯ä¸­çš„ä¸­æ–‡è¦æ±‚æ”¹ä¸ºè‹±æ–‡
            prompt = prompt.replace("Brief description in Chinese", "Brief description in English")
            prompt = prompt.replace("provide a brief description in Chinese", "provide a brief description in English")
            prompt = prompt.replace("description in Chinese", "description in English")

        # æ ¼å¼åŒ–æç¤ºè¯
        return prompt.format(
            title=title,
            abstract=abstract,
            journal=journal,
            authors=authors
        )

    def _call_generic_api(self, prompt: str) -> Dict[str, Any]:
        """
        é€šç”¨APIè°ƒç”¨æ–¹æ³•ï¼Œé€‚ç”¨äºæ‰€æœ‰OpenAIå…¼å®¹çš„API
        
        æ­¤æ–¹æ³•ä¼šè‡ªåŠ¨é€‚é…ä»»ä½•æ”¯æŒOpenAI APIæ ¼å¼çš„AIæä¾›å•†ï¼Œ
        æ— éœ€ä¿®æ”¹ä»£ç å³å¯ä½¿ç”¨æ–°çš„AIæä¾›å•†ã€‚

        Args:
            prompt: æç¤ºè¯

        Returns:
            Dict: APIå“åº”ç»“æœ
        """
        if self.demo_mode:
            # æ¼”ç¤ºæ¨¡å¼ï¼šè¿”å›æ¨¡æ‹Ÿç»“æœ
            return self._get_demo_response(prompt)

        url = f"{self.base_url}/chat/completions"

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": self.model_name,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "response_format": {"type": "json_object"}
        }

        try:
            response = requests.post(url, headers=headers, json=data, timeout=30)
            response.raise_for_status()

            result = response.json()
            content = result['choices'][0]['message']['content']

            # è§£æJSONå“åº”
            return json.loads(content)

        except requests.exceptions.RequestException as e:
            raise Exception(f"{self.provider} APIè¯·æ±‚å¤±è´¥: {e}")
        except json.JSONDecodeError as e:
            raise Exception(f"è§£æAIå“åº”å¤±è´¥: {e}")

    def _call_deepseek_api(self, prompt: str) -> Dict[str, Any]:
        """
        è°ƒç”¨DeepSeek APIï¼ˆä½¿ç”¨é€šç”¨æ–¹æ³•ï¼‰

        Args:
            prompt: æç¤ºè¯

        Returns:
            Dict: APIå“åº”ç»“æœ
        """
        return self._call_generic_api(prompt)

    def _get_demo_response(self, prompt: str) -> Dict[str, Any]:
        """
        è·å–æ¼”ç¤ºæ¨¡å¼çš„æ¨¡æ‹Ÿå“åº”

        Args:
            prompt: æç¤ºè¯

        Returns:
            Dict: æ¨¡æ‹Ÿçš„AIè¯„ä¼°ç»“æœ
        """
        # è§£ææ–‡ç« ä¿¡æ¯
        title = ""
        abstract = ""
        if "Title: " in prompt:
            title_start = prompt.find("Title: ") + 7
            title_end = prompt.find("\n", title_start)
            title = prompt[title_start:title_end].lower()
        
        if "Abstract: " in prompt:
            abstract_start = prompt.find("Abstract: ") + 10
            abstract_end = prompt.find("\nJournal:", abstract_start)
            if abstract_end == -1:
                abstract_end = len(prompt)
            abstract = prompt[abstract_start:abstract_end].lower()

        # æ¨¡æ‹ŸAIçš„å®Œæ•´è¯„ä¼°è¿‡ç¨‹
        full_text = (title + " " + abstract).lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ ¸å¿ƒåº”ç”¨é¢†åŸŸå…³é”®è¯
        application_areas = []
        descriptions = []
        
        # phenotype from genotype
        if any(word in full_text for word in ['phenotype', 'genotype', 'phenotype from genotype']):
            application_areas.append("phenotype from genotype")
            descriptions.append("predicts phenotypes from genotype data")
        
        # life cycle simulation
        if any(word in full_text for word in ['life cycle', 'lifecycle', 'simulation']):
            application_areas.append("life cycle simulation")
            descriptions.append("simulates life cycle processes")
        
        # cell cycle regulator
        if any(word in full_text for word in ['cell cycle', 'cell cycle regulator']):
            application_areas.append("cell cycle regulator")
            descriptions.append("studies cell cycle regulation")
        
        # single-cell multi-omics
        if any(word in full_text for word in ['single-cell', 'single cell', 'multi-omics', 'multiomics']):
            application_areas.append("single-cell multi-omics")
            descriptions.append("integrates single-cell multi-omics data")
        
        # scATAC-seq
        if 'scatac-seq' in full_text or 'scatac' in full_text:
            application_areas.append("scATAC-seq")
            descriptions.append("analyzes scATAC-seq data")
        
        # scRNA-seq
        if 'scrna-seq' in full_text or 'scrna' in full_text:
            application_areas.append("scRNA-seq")
            descriptions.append("analyzes scRNA-seq data")
        
        # chromatin accessibility
        if any(word in full_text for word in ['chromatin accessibility', 'chromatin access']):
            application_areas.append("chromatin accessibility")
            descriptions.append("studies chromatin accessibility")
        
        # gene regulatory network
        if any(word in full_text for word in ['gene regulatory', 'regulatory network']):
            application_areas.append("gene regulatory network")
            descriptions.append("models gene regulatory networks")
        
        # enhancer-gene linking
        if any(word in full_text for word in ['enhancer', 'enhancer-gene', 'enhancer gene']):
            application_areas.append("enhancer-gene linking")
            descriptions.append("links enhancers to genes")
        
        # chromatin potential
        if 'chromatin potential' in full_text:
            application_areas.append("chromatin potential")
            descriptions.append("analyzes chromatin potential")
        
        # GWAS variant enrichment
        if any(word in full_text for word in ['gwas', 'variant enrichment']):
            application_areas.append("GWAS variant enrichment")
            descriptions.append("performs GWAS variant enrichment")
        
        # eQTL
        if 'eqtl' in full_text:
            application_areas.append("eQTL")
            descriptions.append("conducts eQTL analysis")
        
        # metabolomics analysis
        if any(word in full_text for word in ['metabolomics', 'metabolome', 'metabolic profiling', 'metabolite']):
            application_areas.append("metabolomics analysis")
            descriptions.append("analyzes metabolomics data")
        
        # proteomics analysis
        if any(word in full_text for word in ['proteomics', 'proteome', 'protein identification', 'protein quantification']):
            application_areas.append("proteomics analysis")
            descriptions.append("analyzes proteomics data")
        
        # computational metabolomics
        if any(word in full_text for word in ['computational metabolomics', 'metabolomics algorithm', 'metabolomics method']):
            application_areas.append("computational metabolomics")
            descriptions.append("develops computational methods for metabolomics")
        
        # computational proteomics
        if any(word in full_text for word in ['computational proteomics', 'proteomics algorithm', 'proteomics method']):
            application_areas.append("computational proteomics")
            descriptions.append("develops computational methods for proteomics")
        
        # virtual cell
        if any(word in full_text for word in ['virtual cell', 'cell simulation', 'cellular modeling', 'in silico cell']):
            application_areas.append("virtual cell")
            descriptions.append("creates virtual cell models and simulations")
        
        # aging
        if any(word in full_text for word in ['aging', 'ageing', 'senescence', 'longevity', 'aging biology']):
            application_areas.append("aging")
            descriptions.append("studies aging processes and mechanisms")
        
        # foundation model
        if any(word in full_text for word in ['foundation model', 'foundational model', 'multimodal foundation model', 'biology foundation model', 'omics foundation model']):
            application_areas.append("foundation model")
            descriptions.append("develops foundation models for biological data")
        if application_areas:
            relevant = True
            score = min(10, 6 + len(application_areas) * 1)  # åŸºç¡€åˆ†6ï¼Œæ¯åŒ¹é…ä¸€ä¸ªé¢†åŸŸåŠ 1åˆ†
            
            # æ ¹æ®è¯­è¨€è®¾ç½®ç”Ÿæˆæè¿°
            if self.language == 'zh':
                # ä¸­æ–‡æè¿°
                zh_descriptions = {
                    "predicts phenotypes from genotype data": "é¢„æµ‹åŸºå› å‹åˆ°è¡¨å‹",
                    "simulates life cycle processes": "æ¨¡æ‹Ÿç”Ÿå‘½å‘¨æœŸè¿‡ç¨‹",
                    "studies cell cycle regulation": "ç ”ç©¶ç»†èƒå‘¨æœŸè°ƒæ§",
                    "integrates single-cell multi-omics data": "æ•´åˆå•ç»†èƒå¤šç»„å­¦æ•°æ®",
                    "analyzes scATAC-seq data": "åˆ†æscATAC-seqæ•°æ®",
                    "analyzes scRNA-seq data": "åˆ†æscRNA-seqæ•°æ®",
                    "studies chromatin accessibility": "ç ”ç©¶æŸ“è‰²è´¨å¯åŠæ€§",
                    "models gene regulatory networks": "å»ºæ¨¡åŸºå› è°ƒæ§ç½‘ç»œ",
                    "links enhancers to genes": "è¿æ¥å¢å¼ºå­åˆ°åŸºå› ",
                    "analyzes chromatin potential": "åˆ†ææŸ“è‰²è´¨æ½œåŠ›",
                    "performs GWAS variant enrichment": "è¿›è¡ŒGWASå˜å¼‚å¯Œé›†åˆ†æ",
                    "conducts eQTL analysis": "è¿›è¡ŒeQTLåˆ†æ",
                    "analyzes metabolomics data": "åˆ†æä»£è°¢ç»„å­¦æ•°æ®",
                    "analyzes proteomics data": "åˆ†æè›‹ç™½è´¨ç»„å­¦æ•°æ®",
                    "develops computational methods for metabolomics": "å¼€å‘ä»£è°¢ç»„å­¦è®¡ç®—æ–¹æ³•",
                    "develops computational methods for proteomics": "å¼€å‘è›‹ç™½è´¨ç»„å­¦è®¡ç®—æ–¹æ³•",
                    "creates virtual cell models and simulations": "åˆ›å»ºè™šæ‹Ÿç»†èƒæ¨¡å‹å’Œæ¨¡æ‹Ÿ",
                    "studies aging processes and mechanisms": "ç ”ç©¶è¡°è€è¿‡ç¨‹å’Œæœºåˆ¶",
                    "develops foundation models for biological data": "å¼€å‘ç”Ÿç‰©æ•°æ®åŸºç¡€æ¨¡å‹"
                }
                zh_desc = zh_descriptions.get(descriptions[0], descriptions[0])
                description = f"æ–‡ç« {zh_desc}"
                if len(descriptions) > 1:
                    zh_others = [zh_descriptions.get(d, d) for d in descriptions[1:]]
                    description += f"å’Œ{', '.join(zh_others)}"
            else:
                # è‹±æ–‡æè¿°
                description = f"Article {descriptions[0]}"
                if len(descriptions) > 1:
                    description += f" and {', '.join(descriptions[1:])}"
        else:
            relevant = False
            score = 1
            if self.language == 'zh':
                description = "æ–‡ç« ä¸å±äºæŒ‡å®šçš„ç”Ÿç‰©å­¦åº”ç”¨é¢†åŸŸ"
            else:
                description = "Article does not focus on specified biological applications"
            application_areas = []

        return {
            "relevant": relevant,
            "score": score,
            "description": description,
            "application_areas": application_areas
        }

    def _call_kimi_api(self, prompt: str) -> Dict[str, Any]:
        """
        è°ƒç”¨Kimi API (Moonshot)ï¼ˆä½¿ç”¨é€šç”¨æ–¹æ³•ï¼‰

        Args:
            prompt: æç¤ºè¯

        Returns:
            Dict: APIå“åº”ç»“æœ
        """
        return self._call_generic_api(prompt)

    def _call_openai_api(self, prompt: str) -> Dict[str, Any]:
        """
        è°ƒç”¨OpenAI APIï¼ˆä½¿ç”¨é€šç”¨æ–¹æ³•ï¼‰

        Args:
            prompt: æç¤ºè¯

        Returns:
            Dict: APIå“åº”ç»“æœ
        """
        return self._call_generic_api(prompt)


def load_ai_filter(config: Dict[str, Any]) -> AIFilter:
    """
    ä»é…ç½®åˆ›å»ºAIè¿‡æ»¤å™¨

    Args:
        config: å®Œæ•´é…ç½®å­—å…¸

    Returns:
        AIFilter: AIè¿‡æ»¤å™¨å®ä¾‹
    """
    ai_config = config.get('ai_filtering', {})
    if not ai_config.get('enabled', False):
        # è¿”å›ä¸€ä¸ªç¦ç”¨çš„è¿‡æ»¤å™¨
        return AIFilter({'enabled': False, 'model': {}, 'prompt': ''})

    # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ¼”ç¤ºæ¨¡å¼
    demo_mode = ai_config.get('demo_mode', False)
    if demo_mode:
        logger.info("ğŸ¤– AIè¿‡æ»¤å™¨å¯ç”¨æ¼”ç¤ºæ¨¡å¼")
        ai_config['demo_mode'] = True

    return AIFilter(ai_config)


def filter_articles_with_ai(articles: List[Dict[str, Any]], config: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨AIè¿‡æ»¤æ–‡ç« çš„ä¾¿æ·å‡½æ•°

    Args:
        articles: æ–‡ç« åˆ—è¡¨
        config: é…ç½®å­—å…¸

    Returns:
        List[Dict]: è¿‡æ»¤åçš„æ–‡ç« åˆ—è¡¨
    """
    ai_filter = load_ai_filter(config)
    return ai_filter.filter_articles(articles)

